{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Julia Toyama\n",
    "\n",
    "Nome: Pedro Lacerda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Pedro Lacerda\\Downloads\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Ayaka.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu sou cadelinha da lumine com a ayaka e acho ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@hwkenoace @aceasfolk falto ficar doido quando...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gente como faz pizza pra ayaka? n tenho essa r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a ult da ayaka devia seguir os inimigos pois t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ayaka esta nas tuas m√£os https://t.co/bczegdikfo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  eu sou cadelinha da lumine com a ayaka e acho ...              0\n",
       "1  @hwkenoace @aceasfolk falto ficar doido quando...              0\n",
       "2  gente como faz pizza pra ayaka? n tenho essa r...              0\n",
       "3  a ult da ayaka devia seguir os inimigos pois t...              0\n",
       "4   ayaka esta nas tuas m√£os https://t.co/bczegdikfo              0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boa noite para todos menos pra ganyu, ayaka, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q man√© ayato, eu quero saber √© da irm√£ dele qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@shin_kyuu eu farmei pra ayaka e de quebra foi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entrou um whale no meu mundo que fez minha aya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dps de deixar a hu toa boa.l\\nvou voltar pra y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  boa noite para todos menos pra ganyu, ayaka, m...              0\n",
       "1  q man√© ayato, eu quero saber √© da irm√£ dele qu...              1\n",
       "2  @shin_kyuu eu farmei pra ayaka e de quebra foi...              0\n",
       "3  entrou um whale no meu mundo que fez minha aya...              0\n",
       "4  dps de deixar a hu toa boa.l\\nvou voltar pra y...              0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto em quest√£o trata-se de uma personagem no jogo Genshin Impact chamada Kamisato Ayaka. Embora o  jogo seja gr√°tis para jogar, os jogadores podem gastar dinheiro para aumentar a chance e frequ√™ncia de conseguir personagens novos. Foi considerados tweets relevantes aqueles que davam alguma opini√£o sobre a personagem, seja por seu gameplay, est√©tica, personalidade, ou outro aspecto. Da mesma maneira, foram considerados irrelevantes os tweets que apenas mencionavam o nome da personagem sem dar uma opni√£o sobre a mesma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTRA TREINAMENTO\n",
    "\n",
    "#Filtra relevantes\n",
    "filtra_relevantes = train['Classifica√ß√£o'] == 1\n",
    "train_relevantes = train.loc[filtra_relevantes,['Treinamento']]\n",
    "lista_relevantes = train_relevantes[['Treinamento']].values.tolist()\n",
    "\n",
    "#Filtra irrelevantes\n",
    "filtra_irrelevantes = train['Classifica√ß√£o'] == 0\n",
    "train_irrelevantes = train.loc[filtra_irrelevantes, ['Treinamento']]\n",
    "lista_irrelevantes = train_irrelevantes[['Treinamento']].values.tolist()\n",
    "\n",
    "#Filtra tudo \n",
    "#filtra_tudo_treinamento = train['Classifica√ß√£o']\n",
    "#train_tudo_treinamento = train.loc[filtra_tudo_treinamento, ['Treinamento']]\n",
    "lista_tudo_treinamento = train['Treinamento'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queria', 'tanto', 'a', 'espada', 'da', 'ayaka', 'devia', 'ter', 'pego', '@rioumochi', 'mds', '40', 'pulls', '√©', 'bastante', 'at√©', 'l√°', 'vc', 'vai', 'ter', 'muito', 'tipo', 'a', 'ayaka', 'crtz', 'f√©', 'üôèüôèüôè', 'se', 'a', 'ayaka', 'tivesse', 'vindo', 'teria', 'os', 'tres', 'https//tco/rbdyjgy2zb', 'eles', 'q', 'n', 'inventem', 'um', 'rerun', 'do', 'kazuha', 'ou', 'ayaka', 'ou', 'rererun', 'do', 'venti', 'nesse', 'meio', 'tempo', '@sakurafogosa', 'ayaka', 'xingqiu', 'diona', 'e', 'kazuha', 'to', 'tao', 'feliz', 'que', 'meu', 'fav', 'entrou', 'de', 'vez', 'xiquinho', 'eu', 'vo', 'surtar', 'hein', 'eu', 'amo', 'a', 'ayaka', 'se', 'nao', 'tiver', 'ayato', 'gostoso', 'eh', 'boicote', 'viu', 'miojo', 'https//tco/2nqccvkcex', '@twicend', 'gente', 'que', 'arma', 'eh', 'essa', 'da', 'ayaka', 'qualquer', 'coisa', 'que', 'a', 'ayaka', 'fala', 'eu', 'respondo', 'uns', '15', 'min', 'depois', 'com', 'oi', 'amor', 'tava', 'estudando', 'n', 'aguento', 'mais', 'nao', 'conseguir', 'responder', 'minha', 'namorada', 'na', 'hora', 'oficialmente', 'main', 'ayaka', 'agora', '@g4spie', '@softkilllua', 'krl', 'ayaka', 'justamente', 'a', 'q', 'eu', 'quero', 'completei', 'os', 'artefatos', 'da', 'ayaka', 'quero', 'muito', 'trocar', 'a', 'minha', 'conta', 'no', 'genshin', 'por', 'alguma', 'com', 'a', 'ayaka', 'ou', 'baal', 'xingqiu', 'e', 'se', 'tiver', 'sorte', 'o', 'chongyun', 'https//tco/igsk4c4yxd', '@afknowerr', 'meu', 'deus', 'aaar', 'ayaka', 'perfeita', 'e', 'j√°', 'uma', 'das', 'minhas', 'fav', 'eu', 'queria', 'tanto', 'ganhar', 'e', 'consegui', 'no', '50/50', 'e', 'gra√ßas', 'a', 'deus', 'a', 'shogun', 'raiden', 'veio', 'no', '50/50', 'tamb√©m', '@xulianms', 'queria', 'a', 'ayaka', 'https//tco/xpbxdybi2u', '@shin_kyuu', 'eu', 'tenho', 'mona', 'e', 'sucrose', 'queria', 'um', 'kazuha', 'mas', 'eu', 'ia', 'chorar', 'mt', 'se', 'n', 'tivesse', 'a', 'ayaka', 'alsjdkasjkl', 'ayaka', 'eu', 'te', 'amo', 'mas', 'pelo', 'amor', 'de', 'deus', 'eu', 'n√£o', 'aguento', 'mais', 'ce', 'falando', 'a', 'cada', 'tr√™s', 'segundos', 'da', 'um', 'tempo', 'muler', 'a', 'um', 'pique', 'de', 'fazer', 'amizade', '10', 'c', 'a', 'ayaka', 'mal', 'posso', 'esperar', 'ayaka', 'is', 'so', 'precious', 'omg', '@crislaike1', '@garde_naire', '@cerqsthiago', 'oidsjafdios', 'acharam', 'q', 'eu', 'tinha', 'terminado', 'toma', 'um', 'v√≠deo', 'fazendo', 'isso', 'mas', '√©', 'a', 'mona', 'no', 'caso', 'da', 'pra', 'subs', 'com', 'o', 'xinqgiu', 'se', 'n', 'tiver', 'ela', 'e', 'dsclp', 'me', 'meter', 'a', 'ayaka', '√©', 'tudo', 'pra', 'mim', 'https//tco/dbuadx4kt5', 'ayaka', 'te', 'amo', 'demais', 'nunca', 'fui', 'triste', 'com', 'vc', 'üíó', 'vou', 'jogar', 'de', 'ayaka', 'aq', 'na', 'conta', 'do', 'meu', 'irmao', 'eu', 'ainda', 'fico', 'triste', 'quando', 'vejo', 'coisinha', 'da', 'ayaka', 'devia', 'n√£o', 'ter', 'feito', 'a', 'lend√°ria', 'dela', 'pq', 'a√≠', 'n√£o', 'ia', 'gostar', 'tanto', 'proibido', 'entrar', 'no', 'meu', 'mundo', 'de', 'ayaka', 'se', 'o', 'vazamentos', 'do', 'ayato', 'forem', 'verdade', 'ele', 'vai', 'ser', 't√£o', 'divo', 'com', 'a', 'ayaka', 'entrei', 'na', 'conta', 'da', 'mih', 'e', 'agora', 'posso', 'usar', 'a', 'ayaka', 'nunca', 'fui', 'triste', 'vou', 'passar', 'a', 'noite', 'farmando', 'artefato', 'pra', 'ayaka', 'j√°', 'estudei', 'posso', 's√≥', 'ficar', 'vagabundando', 'hoje', 'üòçüñêüèª', 'eu', 'te', 'odeio', 'beidou', 'gorou', 'kazuha', 'traveller', 'yoimiya', 'ayaka', 'e', 'kokomi', 'yae', 'n', 'conta', 'mas', 'eu', 'odeio', 'ela', 'tb', '@edvardneto', 'sim', 'eu', 'pulei', 'a', 'yoimiya', 's√≥', 'por', 'causa', 'da', 'ei', 'mas', 'esperarei', 'o', 'rerun', 'da', 'yoimiya', 'e', 'da', 'ayaka', 'como', 'tamb√©m', 'da', 'eula', 'e', 'xiao', 'https//tco/kxx9lovujx', 'queria', 'mona', 'pra', 'poder', 'usar', 'bennett', 'mona', 'raiden', 'e', 'ayaka', '\\U0001f972', 'sonhei', 'https//tco/qpo6bwhslp', 'to', 'mesmo', 'fazendo', 'cartinha', 'pra', 'ayaka', 'vei', 'qria', 'escrever', 'uma', 'carta', 'pra', 'ayaka', 'mas', 'n√£o', 'consigo', 'demonstrar', 'sentimentos', 'atrav√©s', 'de', 'um', 'texto', '@thebakka', 'ai', 'sim', 'cara', 'eu', 'peguei', 'a', 'ayaka', 'e', 'nao', 'jogo', 'faz', 'tempo', 'voltei', 'a', 'jogar', 'identity', 'v', 'lt/3', 'vou', 'come√ßar', 'a', 'entrar', 'no', 'mundo', 'da', 'anna', 'pra', 'roubar', 'recurso', 'pra', 'melhorar', 'minha', 'ayaka', '@rezhongzhu', 'fodase', 'a', 'ayaka', 'tambem', 'cabe√ßuda', 'minha', 'ayaka', 'ta', 'um', 'lixo', '@manzmilk', 'vai', 'na', 'ayaka', 'que', '√©', 'sucesso', 'o', 'cabelo', 'da', 'ayaka', 'deveria', 'ser', 'assim', 'inv√©s', 'daqueles', 'pompom', 'de', 'poodle', 'üí≠', 'https//tco/azpovgpiva', 'depois', 'd', 'uns', 'quase', '3', 'meses', 'farmando', 'eu', 'terminei', 'a', 'build', 'da', 'ayaka', 'adoro', 'genshin', 'impact', 'https//tco/emum2woycz', '@ifvkarina', 'o', 'permafreeze', 'de', 'milh√µes', 'coma', 'a', 'ayaka', 'https//tco/vp6vfbvk2f', '@brgenshinimpact', 'personagem', 'irrelevante', 'e', 'esquecido', 'posta', 'mais', 'coisa', 'da', 'ayaka', '@sluhkrp', 'kkkkkkk', 'ai', 'deus', 'eu', 'n', 'sei', 'qq', 'eu', 'fa√ßo', 'msm', 'queria', 'a', 'hutao', 'mas', 'imagina', 'fazer', 'duplinha', 'da', 'minha', 'ayaka', 'com', 'ayato', 'num', 'timee', 'um', 'arrependimento', 'n√£o', 'ter', 'rodado', 'no', 'banner', 'da', 'ayaka', 'https//tco/zacyztzwqe', '@scarakitten', 'aria', 'kkk', 'vc', 'nao', 'precisa', 'de', 'c6', 'de', 'nenhum', 'personagem', 'rlx', 'alem', 'doq', 'o', 'thoma', 'e', 'a', 'yelan', 'sao', '4', 'e', 'tipo', 'sla', 'o', 'rerun', 'da', 'ayaka', 'vai', 'demorar', 'oq', 'uns', '9', 'meses', 'sem', 'falar', 'q', 'eu', 'q', 'seguro', 'tiro', 'consegui', 'garantir', 'um', '50/50', 'e', 'um', 'garantido', 'em', 'oq', 'uns', '2', 'meses', '@taikigui', 'ele', 'puxando', 'os', 'bichos', '√≥bvio', 'que', 'vai', 'ser', 'sub', 'amo', 'ela', 'vai', 'juntar', 'tudo', 'pra', 'minha', 'ayaka', 'ultar', 'e', 'congelar', '@wanminleaks', 'ayaka', 'perdeu', 'o', 'lugar', 'de', 'maior', 'cabe√ßa', 'do', 'jogo', 'pra', 'essa', 'ai', 'cara‚Ä¶', 's√≥', 'eu', 'que', 'acho', 'a', 'ayaka', 'e', 'o', 'viajante', 'fofos', 'juntos', 'tipo', '@yun0hime', 'eu', 'pulei', 'a', 'yoi', 'pra', 'pegar', 'a', 'raiden', 'dksndks', 'mas', 'minha', 'raiden', 't√°', 'bem', 'boa', 'c0', 'lvl', '70', 'e', 'com', 'arma', 'lvl', '80', 'j√°', 'saiu', '20k', 'de', 'dano', 'qnd', 'a', 'ult', 'ainda', 'tava', 'lvl', '4', 'upei', 'a', 'ult', 'ontem', 'e', 'sem', 'tds', 'os', 'stacks', 'ela', 'deu', '14k', 't√°', 'machucando', 'mais', 'que', 'a', 'skill', 'lvl', '8', 'da', 'minha', 'ayaka', 'lvl', '90', 'com', 'arma', 'lvl', '90', '0', '@jmflter', 'nossa', 'sim', 'eu', 'achei', 'super', 'daora', 'isso', 'dele', 'trocar', 'pra', 'espada', 'na', 'ult', 'tbm', 'tomara', 'que', 'a', 'anima√ß√£o', 'seja', 'bem', 'feitinha', 'igual', 'da', 'baal', 'e', 'nossa', 'a', 'ult', 'dele', 'deve', 'ficar', 'tao', 'boa', 'com', 'a', 'da', 'ayaka', 't√¥', 'aqui', 'torcendo', 'pelo', 'reencontro', 'dos', 'irm√£os', 'na', 'minha', 'conta', '@emindrss', 'boa', 'boa', 'minha', 'ayaka', 'ta', 'braba', 'tbm', 'm√≥', 'orgulho', 'independente', 'espero', 'q', 'seja', 'jogavel', 'pq', 'se', 'ayaka', 'j√°', '√©', 'uma', 'excelente', 'dps', 'choro', 'todas', 'as', 'noites', 'por', 'n√£o', 'ter', 'pego', 'ela', 'imagine', 'o', 'irm√£o', 'https//tco/qvlgdgy5jg', 'imagina', 'os', 'irmaozinhos', 'ayaka', 'e', 'ayato', 'no', 'msm', 'time', 'fofos', '@howaitoc', 'acho', 'que', '√©', 'normal', 'voc√™', 'tava', 'priorizando', 'a', 'ayaka', 'que', 'esperou', 'tanto', 'üíô', 'eu', 'to', 'querendo', 'muito', 'a', 'hutao', 'depois', 'de', 'ler', 'mais', 'sobre', 'e', 'ver', 'uns', 'v√≠deos', 'j√°', 'gostava', 'pela', 'apar√™ncia', 'e', 'personalidade', 'mas', 'gostei', 'da', 'gameplay', 'tamb√©m', 'lt3', '@sanjikks', '@garde_naire', '@cerqsthiago', 'kkkkkkkkk', 'amg', 'eu', 'coloquei', 'a', 'mona', 'pq', 'meu', 'xingqiu', 'ja', 'tem', 'dona', 'kkkkkkk', 'fica', 'mt', 'incrivel', 'com', 'a', 'ayaka', 'eu', 'sei', 'que', 'vou', 'me', 'arrepender', 'se', 'n√£o', 'rodar', 'que', 'nem', 'foi', 'com', 'a', 'ayaka', 'i', 'just', 'cant', 'help', 'it', 'me', 'acostumei', 'com', 'o', 'diluc', 'batendo', '3', 'vezes', 'no', 'e', 'com', 'cd', 'de', '5seg', 'aquele', 'e', 'da', 'ayaka', 'me', 'mata', '1', 'vez', 's√≥', 'e', '8seg', 'de', 'cd', '@prodby__3racha', 'dei', 'no', 'da', 'ayaka', 'vc', 'vai', 'me', 'dar', 'a', 'ayaka', 'vc', 'vai', 'me', 'dar', 'a', 'ayaka', 'voce', 'vai', 'querer', 'me', 'da', 'a', 'ayaka', 'https//tco/gxuzdm2lop', '@sohnsmile', 'ayaka', 'cunhada', 'querida', '@i4ningguang', 'se', 'vc', 'fosse', 'do', 'europe', 'eu', 'entrava', 'de', 'ayaka', 'todo', 'dia', 'ayaka', '√©', 't√£o', 'perfeita', 'que', '√≥dio', '@dllschr', 'linda', 'na', 'minha', 'ayaka', 'acho', 'que', 'no', 'final', 'n√£o', 'eh', 'surpresa', 'o', 'ayato', 'ser', 'gostoso', 'pq', 'n√©', 'ele', 'eh', 'irm√£o', 'da', 'ayaka', 'a', 'arte', 'da', 'ayaka', 'e', 'da', 'lumine', 'ü§è', 'https//tco/fch63dyqie', '@is2liz', 'com', 'a', 'ayaka', 'eu', 'mato', 'oceanid', 'facil', '@moonllight_vic', 'sim', 'amigo', 'ela', '√©', 'muito', 'linda', 'eu', 'gosto', 'bastante', 'dos', 'personagens', 'de', 'cryo', 'no', 'geral', 'as', 'personalidades', 'e', 'apar√™ncias', 'deles', 's√£o', 'muito', 'lindas', 'fora', 'que', 'a', 'ayaka', '√©', 'muito', 'graciosa', 'üíú', '@shroudluv', 'ele', 'vai', 'ser', 'meu', 'nezu', 'so', 'tenho', '40', 'pulls', 'ainda', 'mas', 'ainda', 'deve', 'demorar', 'mtmt', 'ate', 'ele', 'sair', 'ai', 'eh', 'so', 'ir', 'juntando', 'que', 'nem', 'fiz', 'com', 'a', 'ayaka', 'üôèüôèüôè', 'fazendo', 'carta', 'pra', 'personagem', 'que', 'nem', 'existe', 'credo', 'kkkkkkkk', 'ayaka', 'ti', 'amo', 'gostariadetedizer', 'tentei', 'fazer', 'ficar', 'fofinho', 'mas', 'n√£o', 'consegui', 'pq', 'n', 'sei', 'editar', 'carta', 'https//tco/qnfye3llly', 'quando', 'pulei', 'la', 'minha', 'ayaka', 'n', 'ficou', 'bem', 'nao', 'https//tco/9pw33erzxm', 'https//tco/dllokdmhwu', '@kaeiluc', 'nossa', 'imagina', 'se', 'ele', 'realmente', 'for', 'hydro', 'polearm', 'o', 'melhor', '√©', 'que', 'vai', 'fazer', 'sentido', 'com', 'ele', 'sendo', 'bom', 'pra', 'uma', 'freeze', 'comp', 'com', 'a', 'ayaka', 'uma', 'carta', 'especial', 'do', 'traveler', 'para', 'nossa', 'princesa', 'ayaka', 'üíû', 'gostariadetedizer', 'https//tco/lscgc88umg', 'a', 'fanart', 'gay', 'da', 'lumine', 'com', 'a', 'ayaka', 'vou', 'morrer', 'https//tco/fxric4lnyb', '@lesbitomi', 'eu', 'fui', 'jogar', 'com', 'a', 'ganyu', 'no', 'evento', 'de', 'agora', 'no', 'celular', 'achei', 'horr√≠vel', 'n√£o', 'tem', 'como', 'usar', 'arco', 'nesse', 'neg√≥cio', 'e', 'a', 'ayaka', 'cumpre', 'bem', 'o', 'papel', 'de', 'dps', 'cryo', 'ent√£o', 'bora', 'l√°', 'eu', 'tenho', 'uma', 'conta', 'com', 'ganyu', 'com', 'arco', 'de', 'amos', 'uma', 'ayaka', 'e', 'qiqi', 'de', '5', 'estrelas', 'e', 'queria', 'trocar', 'por', 'uma', 'conta', 'com', 'a', 'baal', 'e', 'a', 'lan√ßa', 'dela', 'se', 'poss√≠vel', '@sofredorapor2d', 'sim', 'a', 'coisa', 'q', 'eu', 'mais', 'gosto', 'na', 'ayaka', 'eh', 'o', 'irmao', 'dela', 'üî•üî•üî•', '@ragnvindrbar', 'e', 's√≥', 'consigo', 'imaginar', 'o', 'cabelo', 'dele', 'banho', 'igual', 'da', 'ayaka', '@castielbobao', '@uminsonia1', '@wanminleaks', 'ta', 'sim', 'confia', 'tirando', 'ayaka', 'talvez', 'kazuha', 'nenhum', 'dos', 'bonecos', 'de', 'inazuma', 's√£o', 't√£o', 'fortes', 'como', 'ganyu', 'xiangling', 'xiao', 'hutao', 's√≥', 'ver', 'a', 'yoimiya', 'que', '√©', 'o', '5', 'de', 'banner', 'mais', 'fraco', 'a', 'raiden', 'que', 'fica', 'bem', 'tr√°s', 'dos', 'outros', 'arcon', 'e', 'a', 'kokomi', 'que', 'tem', 'um', 'kit', 'extremamente', 'duvidoso', '@sidtsx', 'a', 'ayaka', 'chorando', 'porque', 'n√£o', 'tem', 'espada', 'que', 'combine', 'com', 'ela', 'boa', 'noite', 'ayaka', '√©', 'perfeita', '@hyudeko', 'eu', 'tenho', 'ela', 'e', 'quero', 'o', 'irm√£o', 'pra', 'ser', 'aquela', 'coisa', 'bonitinha', 'de', 'familia', 'tipo', 'qnd', 'eu', 'peguei', 'a', 'ganyu', 'e', 'ayaka', 'pq', 'no', 'shingeki', 'q', 'respectivamente', 'as', 'dubladoras', 'sao', 'da', 'kanao', 'e', 'shinobu', 'farmando', 'pra', 'ayakaüëçüèª', 'https//tco/rmqig4f1cr', 'a', 'ayaka', 'fazendo', 'um', 'just', 'dance', 'no', 'neg√≥cio', 'foi', 'lindo', 'https//tco/6cnsybfkwz', 'ayato', 'e', 'ayaka', 'no', 'meu', 'time', 'c', 'o', 'tohma', 'e', 'gorou', '@icutekokomi', 'sim', 'eu', 'nao', 'teria', 'a', 'yoi', 'nem', 'a', 'ayaka', 'peguei', 'a', 'ayaka', 'e', 'a', 'ganyu', 'tambem', 'mas', 'eu', 'nao', 'rodaria', 'nelas', '@katsumightx', 'sim', 'quero', 'ele', 'p', 'colocar', 'com', 'a', 'ayaka', 'e', 'o', 'thomad', 'trenzinho', 'e', 'o', 'pior', '√©', 'que', 'eu', 'peguei', 'a', 'ayaka', 'e', 'a', 'yoimiya', 'nos', 'anteriores', '@fwntom', '@ilysskk', 'ayaka', 'mt', 'mita', 'vou', 'tentar', 'ela', 'no', 'rerun', '@joaoxsaturnio', 'do', 'genshin', 'irmao', 'da', 'ayaka', 'linda', 'entao', 'vai', 'ser', 'lindo', 'igual', 'ela', 'se', 'n√£o', 'tivessem', 'vazado', 'a', 'baal', 'eu', 'n√£o', 'teria', 'ela', 'e', 'sim', 'a', 'ayaka', 'eu', 'tava', 'no', 'garantido', 'e', 'no', 'pity', '65', 'na', 'metade', 'do', 'banner', 'dela', 'foi', 'so', 'ver', 'o', 'vazamento', 'q', 'eu', 'parei', 'de', 'rodar', 'na', 'hora', 'e', 'eu', 'nao', 'me', 'arrependo', 'disso', '@bajitiktoker', 'to', 'assim', 'mas', 'n', 'tenho', 'a', 'ganyu', 'nem', 'a', 'hu', 'tao', 'vc', 'tem', 'a', 'ganyu', 'üòø', 'mas', 'pensando', 'assim', 'talvez', 'eu', 'foque', 'mais', 'na', 'hu', 'tao', 'pq', 'ja', 'tenho', 'a', 'ayaka', 'de', 'monstrinho', 'cryo', 'ne', 'n', 'sei', 'essa', 'cena', '√©', 'incr√≠vel', 'os', 'npcs', 'tremeram', 's√≥', 'de', 'olharem', 'pro', 'leque', 'da', 'ayaka', 'inclusive', 'belas', 'm√£os', 'thoma', 'https//tco/4yzztsbhtp', 'ayaka', 'com', '200', 'de', 'dano', 'cr√≠tico', 'ü•∞', 'ayaka', 'vc', 'eh', 'tao', 'linda', 'pq', 'nao', 'mi', 'namora', '@i4hwtao', 'queria', 'a', 'ayaka', 'nossa', '@yanfeizodiac', 'eu', 'tbm', 's√≥', 'consegui', 'a', 'shogun', 'por', 'causa', 'dos', 'leaks', 'se', 'n√£o', 'teria', 'torrado', 'todas', 'minhas', 'gemas', 'na', 'ayaka', '@i2sh0to', 's√≥', 'consigo', 'pensar', 'na', 'ayaka', '@edvardneto', 'duvido', 'fi', 'esse', 'a√≠', 'vai', 'ser', 'sup', 'da', 'ayaka', 'mulheresnotopo', 'ayaka', '3', 'coroas', 'amanha', 'https//tco/iazfzpu2zf', '@nicolas_pyy', '@popzonebr', 'de', 'respeita', 'a', 'ayaka', 'para', 'de', 'sujar', 'a', 'porra', 'da', 'imagem', 'dela', 'nossa', 'meninas', 'eu', 'amo', 'jogar', 'de', 'ayaka', 'melhor', 'boneca', 'que', 'inventaro', 'roubei', 'essa', 'aqui', 'do', 'wandito', 'pra', 'avisar', 'que', 'a', 'qiqi', 'eh', 'bem', 'maior', 'do', 'que', 'a', 'ayaka', 'e', 'a', 'eula', 'a', 'mulher', 'morta', 'faz', 'mais', 'do', 'que', 'as', 'duas', 'vivas', 'https//tco/59jmwvb3iu', 'essa', 'miss√£o', 'da', 'ayaka', 'nao', 'acaba', 'e', 'essa', 'porra', 'de', 'ficar', 'seguindo', 'ela', 'n', 'sei', 'oq', 'vai', 'te', 'fuder', 'ult', 'da', 'ayaka', 'dando', '25k', 'por', 'corte', 'obrigado', 'bennett', 'https//tco/csuhg2c9it', '@embracenothing', '√©', 'vdd', 'mas', 'sei', 'l√°', 'quando', '√©', 'contra', 'inimigo', 'de', 'fogo', 'eu', 'n√£o', 'tenho', 'muito', 'que', 'reclamar', 'n√£o', 'mas', 'de', '√°gua', 'sim', 'ayaka', '1000x', 'melhor', 'ayaka', 'dando', '10k', 'so', 'no', '√©', 'mds', '@_zackfortune', 'simm', 'o', 'tanto', 'de', 'gente', 'que', 'come√ßou', 'a', 'jogar', 's√≥', 'por', 'causa', 'da', 'ayaka', 'e', 'esperou', 'ela', 'por', 'meses', 'ou', 'at√©', 'mesmo', 'pelo', 'xiao']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FILTRAGEM PARA RELEVANTES TREINAMENTO \"\"\" \n",
    "l=[] # relevantes\n",
    "lista_linhas_relevantes_limpas = []\n",
    "\n",
    "for frase_rel in lista_relevantes:\n",
    "    l.append(frase_rel[0])\n",
    "\n",
    "for f_rel in l:\n",
    "    lista_linhas_relevantes_limpas.append(cleanup(f_rel))\n",
    "    \n",
    "#Separando palavras \n",
    "separadas_rel_T=[]\n",
    "\n",
    "for f_l_rel in lista_linhas_relevantes_limpas:\n",
    "    palavra = f_l_rel.split()\n",
    "    for a in palavra:\n",
    "        separadas_rel_T.append(a)\n",
    "\n",
    "#Transformar em DataFrame\n",
    "serie_relevantes = pd.Series(separadas_rel_T)\n",
    "print(separadas_rel_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FILTRAGEM PARA IRRELEVANTES TREINAMENTO \"\"\"\n",
    "l2=[] # irrelevantes\n",
    "lista_linhas_irrelevantes_limpas = []\n",
    "\n",
    "for frase_ir in lista_irrelevantes:\n",
    "    l2.append(frase_ir[0])\n",
    "\n",
    "for f_ir in l2:\n",
    "    lista_linhas_irrelevantes_limpas.append(cleanup(f_ir))\n",
    "    \n",
    "#Separando palavras \n",
    "separadas_ir_T=[]\n",
    "\n",
    "for f_l_ir in lista_linhas_irrelevantes_limpas:\n",
    "    palavra = f_l_ir.split()\n",
    "    for b in palavra:\n",
    "        separadas_ir_T.append(b)\n",
    "\n",
    "#Transformar em DataFrame\n",
    "serie_irrelevantes = pd.Series(separadas_ir_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ayaka                    303\n",
       "a                        224\n",
       "e                        169\n",
       "eu                       138\n",
       "da                       121\n",
       "                        ... \n",
       "https//tco/eqtjyms8ip      1\n",
       "@lssbian                   1\n",
       "puts                       1\n",
       "talento                    1\n",
       "doido                      1\n",
       "Length: 1709, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"FILTRAGEM PARA TUDO TREINAMENTO \"\"\"\n",
    "separadas_T=[]\n",
    "\n",
    "for frase_t in lista_tudo_treinamento:\n",
    "    frase_t_l = cleanup(frase_t)\n",
    "    for f_t in frase_t_l.split():\n",
    "        separadas_T.append(f_t)\n",
    "    \n",
    "#Transformar em DataFrame\n",
    "serie_treinamento = pd.Series(separadas_T)\n",
    "outra_variavel = serie_treinamento.value_counts()\n",
    "outra_variavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "probR = len(serie_relevantes)/len(serie_treinamento)\n",
    "probI = len(serie_irrelevantes)/len(serie_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade Relevante: 0.32473309608540923\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidade Relevante: {}\".format(probR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade Irrelevante: 0.6752669039145908\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidade Irrelevante: {}\".format(probI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica(text):\n",
    "    limpa = cleanup(text.lower())  \n",
    "    separa = limpa.split()\n",
    "    probR1 = 1\n",
    "    probI1 = 1\n",
    "    for palavra in separa:\n",
    "        if palavra in serie_relevantes.value_counts():\n",
    "            relevante = serie_relevantes.value_counts()[palavra]\n",
    "        else:\n",
    "            relevante = 0\n",
    "        if palavra in serie_irrelevantes.value_counts():\n",
    "            irrelevante = serie_irrelevantes.value_counts()[palavra]\n",
    "        else:\n",
    "            irrelevante = 0\n",
    "        probR1 = probR1 * ((relevante+1)/(len(serie_relevantes)+len(outra_variavel)))\n",
    "        probI1 = probI1 * ((irrelevante+1)/(len(serie_irrelevantes)+len(outra_variavel)))\n",
    "    probabilidadeR = probR1 * probR \n",
    "    probabilidadeI = probI1 * probI\n",
    "    \n",
    "    lista_vazia2 = [probabilidadeR, probabilidadeI]\n",
    "    if probabilidadeR == max(lista_vazia2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "lista_vazia=[]\n",
    "\n",
    "for tweet in test['Teste']:\n",
    "    alguma_letra = classifica(tweet)\n",
    "    lista_vazia.append(alguma_letra)\n",
    "    i+=1\n",
    "lista_vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>41</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>135</td>\n",
       "      <td>65</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0   1  All\n",
       "Classifica√ß√£o              \n",
       "0              105  41  146\n",
       "1               30  24   54\n",
       "All            135  65  200"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array(lista_vazia)\n",
    "pd.crosstab(test['Classifica√ß√£o'], array, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V√™-se que o programa teve uma alta taxa de acertos para os\n",
    "tweets classificados como irrelevantes, e uma taxa significativamente \n",
    "imprecisa para tweets relevantes. Considerando a quantidade de ambos,\n",
    "a taxa de acerto para os insignificantes foi de cerca de 72% (105 de 146),\n",
    "enquanto os relevantes tiveram uma taxa de acerto de 44 % (24 de 54). \n",
    "\n",
    "Essa discrep√¢ncia pode ser explicada por duas raz√µes, sendo elas o modo \n",
    "como qual as mensagens s√£o escritas (abrevia√ß√µes, g√≠rias, falsos negativos\n",
    "‚Äú... n√£o √© nada mal‚Äù, etc), como tamb√©m pelo fato de que um outro\n",
    "personagem ainda n√£o lan√ßado oficialmente no jogo chamado Kamisato Ayato, \n",
    "era frequentemente mencionado nos tweets por ser o irm√£o da personagem \n",
    "usada nesse projeto. Muitas vezes, os tweets estavam dando opini√µes sobre \n",
    "o Ayato, e n√£o sobre a Ayaka. Portanto, mesmo que as mensagens tivessem\n",
    "um conte√∫do relevante, a mera presen√ßa do nome de Ayato no tweet fez o \n",
    "programa interpret√°-lo como irrelevante. \n",
    "\n",
    "Uma poss√≠vel melhoria seria implementar uma fun√ß√£o no programa que, \n",
    "durante a aquisi√ß√£o de tweets, ignora todos aqueles que usam a palavra\n",
    "Ayato. Dessa forma, o pelo programa iria buscar mensagens que s√£o\n",
    "relevantes apenas para a personagem em quest√£o. Assim, poder-se-ia ter uma \n",
    "classifica√ß√£o de palavras que melhor condiz com a real relev√¢ncia do tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
